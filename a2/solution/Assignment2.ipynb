{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danil Timofeev, AI01 \\\n",
    "d.timofeev@innopolis.university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-sensitive Spelling Correction\n",
    "\n",
    "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
    "\n",
    "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
    "\n",
    "Useful links:\n",
    "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
    "- [Norvig's dataset](https://norvig.com/big.txt)\n",
    "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
    "\n",
    "Grading:\n",
    "- 60 points - Implement spelling correction\n",
    "- 20 points - Justify your decisions\n",
    "- 20 points - Evaluate on a test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement context-sensitive spelling correction\n",
    "\n",
    "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
    "\n",
    "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
    "\n",
    "You may also want to implement:\n",
    "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
    "- some recent (or not very recent) paper on this topic,\n",
    "- solution which takes into account keyboard layout and associated misspellings,\n",
    "- efficiency improvement to make the solution faster,\n",
    "- any other idea of yours to improve the Norvigâ€™s solution.\n",
    "\n",
    "IMPORTANT:  \n",
    "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
    "- Your implementation\n",
    "- Analysis of why the implemented approach is suggested\n",
    "- Improvements of the original approach that you have chosen to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['his is your example string with some misspelled words']\n"
     ]
    }
   ],
   "source": [
    "def load_fivegrams(file_path):\n",
    "    fivegrams = {}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            frequency = int(parts[0])\n",
    "            fivegram = tuple(parts[1:])\n",
    "            fivegrams[fivegram] = frequency\n",
    "    return fivegrams\n",
    "\n",
    "\n",
    "def generate_candidate_words(word, dictionary, max_distance=1):\n",
    "    \"\"\"Generate candidate corrections for a word within a given edit distance.\"\"\"\n",
    "    candidates = set()\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "    # Deletion\n",
    "    candidates.update(word[:i] + word[i + 1 :] for i in range(len(word)))\n",
    "    # Transposition\n",
    "    candidates.update(\n",
    "        word[:i] + word[i + 1] + word[i] + word[i + 2 :] for i in range(len(word) - 1)\n",
    "    )\n",
    "    # Alteration\n",
    "    candidates.update(\n",
    "        word[:i] + c + word[i + 1 :] for i in range(len(word)) for c in alphabet\n",
    "    )\n",
    "    # Insertion\n",
    "    candidates.update(\n",
    "        word[:i] + c + word[i:] for i in range(len(word) + 1) for c in alphabet\n",
    "    )\n",
    "\n",
    "    return [w for w in candidates if w in dictionary]\n",
    "\n",
    "\n",
    "def find_best_correction(word, context, fivegrams, dictionary):\n",
    "    candidates = generate_candidate_words(word, dictionary)\n",
    "    # Include the original word in case it's the best choice\n",
    "    candidates.append(word)\n",
    "    max_frequency = -1\n",
    "    best_candidate = word\n",
    "\n",
    "    for candidate in candidates:\n",
    "        for i in range(max(0, len(context) - 4), len(context)):\n",
    "            potential_context = (\n",
    "                context[max(0, i - 4) : i]\n",
    "                + [candidate]\n",
    "                + context[i + 1 : min(i + 5, len(context))]\n",
    "            )\n",
    "            potential_fivegram = tuple(potential_context)\n",
    "            frequency = fivegrams.get(potential_fivegram, 0)\n",
    "            if frequency > max_frequency:\n",
    "                max_frequency = frequency\n",
    "                best_candidate = candidate\n",
    "\n",
    "    return best_candidate\n",
    "\n",
    "\n",
    "def correct_spelling(input_strings, fivegrams):\n",
    "    # Build a dictionary from the fivegrams\n",
    "    dictionary = set(word for fivegram in fivegrams for word in fivegram)\n",
    "\n",
    "    corrected_strings = []\n",
    "    for input_string in input_strings:\n",
    "        words = input_string.split()\n",
    "        corrected_words = []\n",
    "        for i, word in enumerate(words):\n",
    "            if word not in dictionary:\n",
    "                context = words[max(0, i - 4) : i + 5]  # Get 4 words before and after\n",
    "                correction = find_best_correction(word, context, fivegrams, dictionary)\n",
    "                corrected_words.append(correction)\n",
    "            else:\n",
    "                corrected_words.append(word)\n",
    "        corrected_strings.append(\" \".join(corrected_words))\n",
    "    return corrected_strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your decisions\n",
    "\n",
    "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
    "- Which ngram dataset to use\n",
    "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
    "- Beam search parameters\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using a Five-gram Model for Context \\\n",
    "    Decision: The code uses a five-gram model to provide context for spelling corrections.\n",
    "\n",
    "    Justification: Five-grams strike a balance between offering a rich context and managing data sparsity. They provide enough surrounding words to make informed decisions about the most probable correction based on not just the immediate adjacent words but a broader sentence context. This is particularly useful for distinguishing between words that are commonly confused or for choosing the correct spelling in context-sensitive situations.\n",
    "\n",
    "2. Simple Edit Operations for Generating Candidates \\\n",
    "    Decision: The candidate generation function (generate_candidate_words) creates possible corrections through four types of edit operations: deletions, transpositions, alterations, and insertions.\n",
    "\n",
    "    Justification: These operations are based on the most common types of spelling errors, reflecting real-world typing mistakes. Limiting the generation to these operations keeps the candidate set relevant and manageable, improving efficiency while covering a wide range of potential errors.\n",
    "\n",
    "3. Inclusion of the Original Word in Candidates \\\n",
    "    Decision: The original word is included in the set of candidates for correction.\n",
    "\n",
    "    Justification: Including the original word accounts for cases where the word may not be present in the dictionary (used for generating candidates) but is still correct. This is important for handling proper nouns, technical terms, or newly coined words not captured in the dataset.\n",
    "\n",
    "4. Selection of Best Correction Based on Frequency \\\n",
    "    Decision: The correction chosen is the one that, when inserted into the context, forms the most frequent five-gram.\n",
    "\n",
    "    Justification: This approach leverages the frequency information from the five-gram dataset to choose corrections that are not only contextually appropriate but also statistically probable. It's based on the assumption that more frequently occurring word sequences are more likely to be correct, a principle grounded in the statistical nature of language use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on a test set\n",
    "\n",
    "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"i can't believe how beautiful this place is\", 'their going to join us later at the resturant.', 'she has a very unique way of thinking', \"it's definitely holder than yesterday\", 'could you be more pacific about what happened', 'he excersises regularly to stay healthy', 'the accommodation was not what we expected', 'i relieved a letter in the mail', 'the museum is closed on wendesday.', 'their new policy could affect us ally', \"it's an opportunity i can't miss\", 'we need to dress the issue immediately', 'i recommend taking a different routes', 'hers always had trouble with rythm.', 'this is a separate issue from what we discussed', 'lets keep it confidential for now just between you and ib', 'she was greatful for the help she received', 'i appreciate your patience during this time', 'he preferred the blue shirt over the red ones', 'please ensure all your belonging are securred.', 'im looking forward to receiving your feedbacks', 'the argument was irrelevant to the discussions', 'were committed to providing excellent service', \"it's an environmentally friendly product\", 'the government has announced a new plans', 'please fill out the questionnaire by tomorrow', 'his response was inappropriate under the circumstances', 'she has a deep knowledge of the subject', 'weill need to calibrate the equipment again', 'the procedure will take place tomorrow morning']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example usage\n",
    "file_path = \"../data/fivegrams.txt\"\n",
    "input_strings = pd.read_csv('../data/test/test.csv')['Misspelled'].str.lower().tolist()\n",
    "fivegrams = load_fivegrams(file_path)\n",
    "corrected_strings = correct_spelling(input_strings, fivegrams)\n",
    "\n",
    "print(corrected_strings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
